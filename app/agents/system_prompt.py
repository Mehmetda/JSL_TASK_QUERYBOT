"""
Dynamic System Prompt Generator for Medical QueryBot
"""
import sqlite3
from typing import Dict, List, Any
import re
import os
from openai import OpenAI

def get_database_schema_info(conn: sqlite3.Connection) -> str:
    """Get comprehensive database schema information"""
    cursor = conn.cursor()
    
    # Get all tables
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = cursor.fetchall()
    
    schema_info = []
    
    for table in tables:
        table_name = table[0]
        
        # Skip system tables
        if table_name in ['sqlite_sequence']:
            continue
            
        # Get table info
        cursor.execute(f"PRAGMA table_info({table_name})")
        columns = cursor.fetchall()
        
        # Get record count
        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
        count = cursor.fetchone()[0]
        
        # Format columns
        col_info = []
        for col in columns:
            col_name = col[1]
            col_type = col[2]
            is_pk = bool(col[5])
            pk_marker = " (PRIMARY KEY)" if is_pk else ""
            col_info.append(f"{col_name} ({col_type}){pk_marker}")
        
        schema_info.append(f"""
ðŸ“‹ {table_name} ({count} kayÄ±t):
  - {', '.join(col_info)}""")
    
    return "\n".join(schema_info)

def generate_system_prompt(conn: sqlite3.Connection) -> str:
    """Generate comprehensive system prompt for medical database queries"""
    
    schema_info = get_database_schema_info(conn)
    
    system_prompt = f"""Sen bir tÄ±bbi veritabanÄ± uzmanÄ±sÄ±n ve SQLite veritabanÄ± Ã¼zerinde Ã§alÄ±ÅŸÄ±yorsun. KullanÄ±cÄ±larÄ±n doÄŸal dil sorularÄ±nÄ± SQL sorgularÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in tasarlandÄ±n.

## ðŸ¥ VERÄ°TABANI ÅžEMASI

{schema_info}

## ðŸ”— TABLO Ä°LÄ°ÅžKÄ°LERÄ°

- **json_patients** â†” **json_admissions**: subject_id ile baÄŸlantÄ±lÄ±
- **json_admissions** â†” **json_transfers**: hadm_id ile baÄŸlantÄ±lÄ±  
- **json_admissions** â†” **json_providers**: admit_provider_id ile baÄŸlantÄ±lÄ±
- **json_patients** â†” **json_transfers**: subject_id ile baÄŸlantÄ±lÄ±

## ðŸ“Š VERÄ° TÄ°PLERÄ° VE AÃ‡IKLAMALAR

### Hasta Bilgileri (json_patients)
- **subject_id**: Hasta benzersiz kimliÄŸi
- **gender**: Cinsiyet (M/F)
- **anchor_age**: YaÅŸ
- **anchor_year**: Referans yÄ±lÄ±
- **dod**: Ã–lÃ¼m tarihi (varsa)

### YatÄ±ÅŸ Bilgileri (json_admissions)  
- **hadm_id**: YatÄ±ÅŸ benzersiz kimliÄŸi
- **admittime**: YatÄ±ÅŸ zamanÄ±
- **dischtime**: Ã‡Ä±kÄ±ÅŸ zamanÄ±
- **admission_type**: YatÄ±ÅŸ tipi (EMERGENCY, ELECTIVE, vb.)
- **admission_location**: YatÄ±ÅŸ yeri
- **discharge_location**: Ã‡Ä±kÄ±ÅŸ yeri
- **insurance**: Sigorta bilgisi
- **race**: Irk bilgisi
- **marital_status**: Medeni durum

### Transfer Bilgileri (json_transfers)
- **transfer_id**: Transfer benzersiz kimliÄŸi
- **eventtype**: Transfer tipi (admit, transfer, discharge)
- **careunit**: BakÄ±m birimi
- **intime**: GiriÅŸ zamanÄ±
- **outtime**: Ã‡Ä±kÄ±ÅŸ zamanÄ±

### SaÄŸlÄ±k Personeli (json_providers)
- **provider_id**: Personel kimliÄŸi
- **npi**: Ulusal saÄŸlÄ±k personeli kimliÄŸi
- **dea**: DEA numarasÄ±

## ðŸŽ¯ SORU TÄ°PLERÄ° VE Ã–RNEKLER

### SayÄ±sal Sorgular
- "KaÃ§ hasta var?" â†’ `SELECT COUNT(*) FROM json_patients`
- "KaÃ§ yatÄ±ÅŸ var?" â†’ `SELECT COUNT(*) FROM json_admissions`
- "KaÃ§ transfer var?" â†’ `SELECT COUNT(*) FROM json_transfers`

### Demografik Sorgular
- "HastalarÄ±n yaÅŸ daÄŸÄ±lÄ±mÄ± nasÄ±l?" â†’ `SELECT anchor_age, COUNT(*) FROM json_patients GROUP BY anchor_age`
- "Cinsiyet daÄŸÄ±lÄ±mÄ± nedir?" â†’ `SELECT gender, COUNT(*) FROM json_patients GROUP BY gender`
- "Hangi Ä±rktan kaÃ§ hasta var?" â†’ `SELECT race, COUNT(*) FROM json_admissions GROUP BY race`

### YatÄ±ÅŸ SorgularÄ±
- "Acil yatÄ±ÅŸlar kaÃ§ tane?" â†’ `SELECT COUNT(*) FROM json_admissions WHERE admission_type = 'EMERGENCY'`
- "Hangi yatÄ±ÅŸ yerlerinden kaÃ§ hasta geldi?" â†’ `SELECT admission_location, COUNT(*) FROM json_admissions GROUP BY admission_location`
- "Sigorta tÃ¼rlerine gÃ¶re daÄŸÄ±lÄ±m?" â†’ `SELECT insurance, COUNT(*) FROM json_admissions GROUP BY insurance`

### Transfer SorgularÄ±
- "Hangi bakÄ±m birimlerinde kaÃ§ transfer var?" â†’ `SELECT careunit, COUNT(*) FROM json_transfers GROUP BY careunit`
- "Transfer tiplerine gÃ¶re daÄŸÄ±lÄ±m?" â†’ `SELECT eventtype, COUNT(*) FROM json_transfers GROUP BY eventtype`

### Zaman BazlÄ± Sorgular
- "Son 30 gÃ¼nde kaÃ§ yatÄ±ÅŸ var?" â†’ `SELECT COUNT(*) FROM json_admissions WHERE admittime >= date('now', '-30 days')`
- "2024 yÄ±lÄ±nda kaÃ§ hasta geldi?" â†’ `SELECT COUNT(*) FROM json_admissions WHERE strftime('%Y', admittime) = '2024'`

### Ä°liÅŸkisel Sorgular
- "Hangi hastalar birden fazla yatÄ±ÅŸ yapmÄ±ÅŸ?" â†’ `SELECT subject_id, COUNT(*) FROM json_admissions GROUP BY subject_id HAVING COUNT(*) > 1`
- "Hangi doktorlar en Ã§ok hasta kabul etmiÅŸ?" â†’ `SELECT admit_provider_id, COUNT(*) FROM json_admissions GROUP BY admit_provider_id ORDER BY COUNT(*) DESC`

## âš ï¸ Ã–NEMLÄ° KURALLAR

1. **Sadece SELECT sorgularÄ±** oluÅŸtur - INSERT, UPDATE, DELETE yasak
2. **Tek SQL statement** dÃ¶ndÃ¼r - Birden fazla statement yasak
3. **NoktalÄ± virgÃ¼l kullanma** - SQL statement sonunda ; koyma
4. **GÃ¼venli sorgular** yaz - SQL injection'a karÅŸÄ± dikkatli ol
5. **JOIN kullan** - Ä°liÅŸkili tablolarÄ± birleÅŸtir
6. **TÃ¼rkÃ§e cevap ver** - KullanÄ±cÄ± TÃ¼rkÃ§e soruyorsa TÃ¼rkÃ§e yanÄ±tla
7. **AnlamlÄ± sonuÃ§lar** dÃ¶ndÃ¼r - Sadece sayÄ± deÄŸil, aÃ§Ä±klama da ekle
8. **Hata durumunda** - Veri bulunamazsa aÃ§Ä±k mesaj ver

## ðŸ” SORU ANALÄ°ZÄ°

KullanÄ±cÄ± sorusunu analiz et:
1. **Ana konu**: Hasta, yatÄ±ÅŸ, transfer, personel?
2. **Sorgu tipi**: SayÄ±m, daÄŸÄ±lÄ±m, filtreleme, iliÅŸki?
3. **Zaman aralÄ±ÄŸÄ±**: Belirli tarih, dÃ¶nem?
4. **Gruplama**: Hangi alana gÃ¶re grupla?
5. **SÄ±ralama**: Hangi kritere gÃ¶re sÄ±rala?

## ðŸ“ Ã–RNEK Ã‡IKTI FORMATI

```sql
-- KullanÄ±cÄ± sorusu: "KaÃ§ erkek hasta var?"
SELECT 
    gender,
    COUNT(*) as hasta_sayisi
FROM json_patients 
WHERE gender = 'M'
GROUP BY gender;
```

Bu sistem prompt'u kullanarak kullanÄ±cÄ±larÄ±n doÄŸal dil sorularÄ±nÄ± doÄŸru SQL sorgularÄ±na dÃ¶nÃ¼ÅŸtÃ¼r ve anlamlÄ± sonuÃ§lar Ã¼ret."""

    return system_prompt

def get_enhanced_system_prompt(conn: sqlite3.Connection) -> str:
    """Get enhanced system prompt with additional context"""
    base_prompt = generate_system_prompt(conn)
    
    # Add additional context
    enhanced_prompt = f"""{base_prompt}

## ðŸš€ GELÄ°ÅžMÄ°Åž Ã–ZELLÄ°KLER

### AkÄ±llÄ± VarsayÄ±mlar
- KullanÄ±cÄ± "hasta" dediÄŸinde â†’ json_patients tablosu
- KullanÄ±cÄ± "yatÄ±ÅŸ" dediÄŸinde â†’ json_admissions tablosu  
- KullanÄ±cÄ± "transfer" dediÄŸinde â†’ json_transfers tablosu
- KullanÄ±cÄ± "doktor/personel" dediÄŸinde â†’ json_providers tablosu

### TÃ¼rkÃ§e-Ä°ngilizce EÅŸleÅŸtirme
- hasta â†’ patient
- yatÄ±ÅŸ â†’ admission
- transfer â†’ transfer
- doktor â†’ provider
- yaÅŸ â†’ age
- cinsiyet â†’ gender
- yatÄ±ÅŸ yeri â†’ admission_location
- Ã§Ä±kÄ±ÅŸ yeri â†’ discharge_location

### YaygÄ±n Hata DÃ¼zeltmeleri
- "hastane" â†’ "hospital" (veritabanÄ±nda yok, admission_location kullan)
- "klinik" â†’ "careunit" 
- "servis" â†’ "careunit"
- "bÃ¶lÃ¼m" â†’ "careunit"

Bu bilgileri kullanarak kullanÄ±cÄ± sorularÄ±nÄ± en doÄŸru ÅŸekilde SQL sorgularÄ±na dÃ¶nÃ¼ÅŸtÃ¼r."""

    return enhanced_prompt


# ---- Minimal RAG over schema: keyword-based top-K retriever ----

def _tokenize(text: str) -> List[str]:
    return re.findall(r"[a-zA-Z0-9_]+", text.lower())


def get_relevant_schema_snippets(conn: sqlite3.Connection, question: str, top_k: int = 3) -> str:
    """Select top-k tables/columns relevant to the question using simple token overlap.
    This is a lightweight alternative to embeddings for Task 2.
    """
    # Lightweight synonym expansion (TR -> EN/field hints)
    synonym_map = {
        "hasta": ["patient", "json_patients", "subject_id", "gender", "age", "anchor_age"],
        "yas": ["age", "anchor_age"],
        "yaÅŸ": ["age", "anchor_age"],
        "cinsiyet": ["gender"],
        "yatÄ±ÅŸ": ["admission", "json_admissions", "hadm_id", "admission_type", "admittime", "dischtime"],
        "yatis": ["admission", "json_admissions", "hadm_id", "admission_type"],
        "yatÄ±ÅŸ tipi": ["admission_type"],
        "doktor": ["provider", "json_providers", "admit_provider_id", "provider_id"],
        "personel": ["provider", "json_providers"],
        "transfer": ["transfer", "json_transfers", "careunit", "eventtype"],
        "bakim birimi": ["careunit"],
        "bakÄ±m birimi": ["careunit"],
        "servis": ["careunit"],
        "klinik": ["careunit"],
    }

    expanded = question.lower()
    for tr, hints in synonym_map.items():
        if tr in expanded:
            expanded += " " + " ".join(hints)

    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [r[0] for r in cursor.fetchall() if r[0] != 'sqlite_sequence']

    q_tokens = set(_tokenize(expanded))
    scored: List[tuple[str, int, List[str]]] = []

    for table in tables:
        cursor.execute(f"PRAGMA table_info({table})")
        cols = cursor.fetchall()
        col_names = [c[1] for c in cols]
        corpus = f"{table} " + " ".join(col_names)
        t_tokens = set(_tokenize(corpus))
        score = len(q_tokens & t_tokens)
        scored.append((table, score, col_names))

    scored.sort(key=lambda x: x[1], reverse=True)
    top = [s for s in scored[:top_k] if s[1] > 0] or scored[: min(top_k, len(scored))]

    parts: List[str] = []
    for table, _, col_names in top:
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {table}")
            count = cursor.fetchone()[0]
        except Exception:
            count = 0
        parts.append(f"- Table: {table} ({count} rows)\n  Columns: {', '.join(col_names)}")

    return "\n".join(parts) if parts else "- (No specific relevant tables detected; use overall schema above)"


def get_contextual_system_prompt(conn: sqlite3.Connection, question: str) -> str:
    base = get_enhanced_system_prompt(conn)
    # Switchable: hybrid vs keyword-only
    use_hybrid = os.getenv("RAG_HYBRID", "0") == "1"
    if use_hybrid:
        relevant = get_hybrid_relevant_schema_snippets(conn, question, top_k=int(os.getenv("RAG_TOP_K", "3")))
    else:
        relevant = get_relevant_schema_snippets(conn, question, top_k=int(os.getenv("RAG_TOP_K", "3")))
    return f"{base}\n\n## ðŸ”Ž Ä°lgili Åžema (Soruya gÃ¶re)\n{relevant}\n\nYukarÄ±daki ilgili ÅŸemayÄ± kullanarak tek ve gÃ¼venli bir SELECT sorgusu Ã¼ret."


# ---- Hybrid RAG (semantic + keyword) over schema ----

def _build_schema_docs(conn: sqlite3.Connection) -> List[Dict[str, str]]:
    cursor = conn.cursor()
    cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
    tables = [r[0] for r in cursor.fetchall() if r[0] != 'sqlite_sequence']
    docs: List[Dict[str, str]] = []
    for table in tables:
        cursor.execute(f"PRAGMA table_info({table})")
        cols = cursor.fetchall()
        for col in cols:
            col_name = col[1]
            col_type = col[2]
            text = f"table: {table} | column: {col_name} | type: {col_type}"
            docs.append({"table": table, "column": col_name, "text": text})
        # Also a table-level doc
        texts = ", ".join([c[1] for c in cols])
        docs.append({"table": table, "column": "*", "text": f"table: {table} | columns: {texts}"})
    return docs


def _embed_texts(texts: List[str]) -> List[List[float]]:
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")
    # Batch embed
    res = client.embeddings.create(model=model, input=texts)
    return [d.embedding for d in res.data]


def _cosine(a: List[float], b: List[float]) -> float:
    import math
    dot = sum(x*y for x, y in zip(a, b))
    na = math.sqrt(sum(x*x for x in a))
    nb = math.sqrt(sum(x*x for x in b))
    if na == 0 or nb == 0:
        return 0.0
    return dot / (na * nb)


def get_hybrid_relevant_schema_snippets(conn: sqlite3.Connection, question: str, top_k: int = 3) -> str:
    """Hybrid retrieval: semantic (embeddings) + keyword/metadata scoring."""
    # Build docs
    docs = _build_schema_docs(conn)
    if not docs:
        return get_relevant_schema_snippets(conn, question, top_k)

    # Semantic scores
    try:
        q_emb = _embed_texts([question])[0]
        doc_embs = _embed_texts([d["text"] for d in docs])
        sem_scores = [_cosine(q_emb, e) for e in doc_embs]
    except Exception:
        # Fallback to keyword-only on embedding error
        return get_relevant_schema_snippets(conn, question, top_k)

    # Keyword/metadata score (reuse tokenizer + synonyms)
    synonym_text = question.lower()
    # reuse synonym_map from earlier function by light expansion
    # (avoid ref duplication: call get_relevant_schema_snippets to expand)
    expanded_snippet = get_relevant_schema_snippets(conn, question, top_k=0)  # returns guidance text; we won't use
    q_tokens = set(_tokenize(synonym_text))

    kw_scores: List[int] = []
    for d in docs:
        t_tokens = set(_tokenize(d["text"]))
        kw_scores.append(len(q_tokens & t_tokens))

    alpha = float(os.getenv("RAG_ALPHA", "0.7"))
    combined = [(i, alpha*sem_scores[i] + (1-alpha)*(kw_scores[i] > 0)) for i in range(len(docs))]
    combined.sort(key=lambda x: x[1], reverse=True)

    # Aggregate by table, keep best per table
    table_best: Dict[str, float] = {}
    for idx, sc in combined:
        tb = docs[idx]["table"]
        if tb not in table_best:
            table_best[tb] = sc
        if len(table_best) >= max(top_k, 1):
            # we still continue but limit will apply on formatting
            pass

    # Format top-k tables with columns
    ranked_tables = sorted(table_best.items(), key=lambda x: x[1], reverse=True)[:top_k]
    out_lines: List[str] = []
    cursor = conn.cursor()
    for tb, _ in ranked_tables:
        try:
            cursor.execute(f"SELECT COUNT(*) FROM {tb}")
            count = cursor.fetchone()[0]
        except Exception:
            count = 0
        cursor.execute(f"PRAGMA table_info({tb})")
        cols = cursor.fetchall()
        col_names = [c[1] for c in cols]
        out_lines.append(f"- Table: {tb} ({count} rows)\n  Columns: {', '.join(col_names)}")
    return "\n".join(out_lines) if out_lines else get_relevant_schema_snippets(conn, question, top_k)
