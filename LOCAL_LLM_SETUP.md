# Local LLM Setup Guide

This guide explains how to run the project with a local LLM (e.g., Llama 7B) instead of OpenAI.

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Model Configuration

Configure the model in `config.py`:

```python
# Default model (small & fast)
LLM_MODEL_NAME = "microsoft/DialoGPT-medium"

# For Llama 7B (larger, better quality)
# LLM_MODEL_NAME = "meta-llama/Llama-2-7b-chat-hf"
```

### 3. Test the Application

```bash
python test_local_llm.py
```

### 4. Run the App

```bash
streamlit run app/ui/streamlit_app.py
```

## ğŸ“‹ Supported Models

### Small Models (Fast, low RAM)
- `microsoft/DialoGPT-small` (varsayÄ±lan fallback)
- `microsoft/DialoGPT-medium`

### Llama Models (Better performance, more RAM)
- `meta-llama/Llama-2-7b-chat-hf` (Ã¶nerilen)
- `meta-llama/Llama-2-7b-hf`

## âš™ï¸ Configuration Options

In `config.py` you may set:

```python
# LLM Model
LLM_MODEL_NAME = "meta-llama/Llama-2-7b-chat-hf"

# Embedding Model (for semantic search)
EMBEDDING_MODEL = "sentence-transformers/all-MiniLM-L6-v2"

# GPU usage
USE_GPU = True  # use GPU if available

# Database path
DATABASE_PATH = "app/db/demo.sqlite"
```

## ğŸ”§ System Requirements

### Minimum
- **RAM**: 8GB (for DialoGPT)
- **Disk**: 2GB free
- **Python**: 3.8+

### Recommended (Llama 7B)
- **RAM**: 16GB+
- **GPU**: NVIDIA GPU (8GB+ VRAM)
- **Disk**: 10GB+

## ğŸ› Troubleshooting

### Model Load Error
```bash
# Clear cache
rm -rf ~/.cache/huggingface/

# Retry
python test_local_llm.py
```

### GPU Usage
```python
# Disable GPU in config.py
USE_GPU = False
```

### Out of Memory
Use a smaller model:
```python
LLM_MODEL_NAME = "microsoft/DialoGPT-small"
```

## ğŸ“Š Performance Comparison

| Model | Boyut | RAM | HÄ±z | Kalite |
|-------|-------|-----|-----|--------|
| DialoGPT-small | ~300MB | 2GB | Ã‡ok HÄ±zlÄ± | Orta |
| DialoGPT-medium | ~1.5GB | 4GB | HÄ±zlÄ± | Ä°yi |
| Llama-2-7b | ~13GB | 16GB | YavaÅŸ | Ã‡ok Ä°yi |

## ğŸ”„ Switching from OpenAI

Project can run fully local:
- âœ… No OpenAI API key
- âœ… No internet required
- âœ… Data stays on device
- âœ… No API cost

## ğŸ“ Notes

- First run downloads the model (requires internet)
- Models are cached for faster subsequent runs
- Uses GPU automatically if available
- Works on CPU too (slower)
